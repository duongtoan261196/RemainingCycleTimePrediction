{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb255167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import dirname\n",
    "root_path = dirname(dirname(os.getcwd()))\n",
    "print(root_path)\n",
    "import sys\n",
    "sys.path.append(root_path + '/RemainingCycleTimePrediction/2_Scripts/')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from Event_log_processing_utils import Extract_trace_and_temporal_features, Extract_prefix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "data_dir = root_path + '/RemainingCycleTimePrediction/1_Data/'\n",
    "project_dir = root_path + '/RemainingCycleTimePrediction/'\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.config.experimental.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32c7935",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f3e9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'BPIC20'\n",
    "# data_name = 'Helpdesk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff93497",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_all = pd.read_csv(data_dir+data_name+\"_processed_all.csv\")\n",
    "tab_train= pd.read_csv(data_dir+data_name+\"_processed_train.csv\")\n",
    "tab_test = pd.read_csv(data_dir+data_name+\"_processed_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d35e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics of the dataset\n",
    "lines, lines_t, lines_t2, lines_t3, lines_t4 = Extract_trace_and_temporal_features(tab_all)\n",
    "print(\"num_cases: {}\".format(len(tab_all['Case_ID'].unique())))\n",
    "print(\"num_activities: {}\".format(len(tab_all[\"Activity\"].unique())))\n",
    "print(\"num_events: {}\".format(len(tab_all)))\n",
    "avglen = round(np.mean([len(x) for x in lines]), 2)\n",
    "print(\"avg_case_len: {}\".format(avglen))\n",
    "maxlen = max([len(x) for x in lines]) #find maximum line size\n",
    "print(\"max_case_len: {}\".format(maxlen))\n",
    "print(\"avg_case_duration: {}\".format(round(np.mean([sublist[-1] for sublist in lines_t2])/86400, 2)))\n",
    "print(\"max_case_duration: {}\".format(round(max([sublist[-1] for sublist in lines_t2])/86400, 2)))\n",
    "print(\"min_case_duration: {}\".format(round(min([sublist[-1] for sublist in lines_t2])/86400, 2)))\n",
    "list_unique_line = []\n",
    "for line in lines:\n",
    "    if line not in list_unique_line:\n",
    "        list_unique_line.append(line)\n",
    "print(\"variants: {}\".format(len(list_unique_line)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0540c868",
   "metadata": {},
   "source": [
    "## Prepare inputs and outputs for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55090026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prepare_X_Y_remaining_time(tab, list_activities, divisor, divisor2, divisor_rt, encoder, maxlen):\n",
    "    lines, lines_t, lines_t2, lines_t3, lines_t4 = Extract_trace_and_temporal_features(tab)\n",
    "    prefixes, outputs = Extract_prefix(lines, lines_t, lines_t2, lines_t3, lines_t4)\n",
    "    num_samples = len(prefixes[0])\n",
    "#     [sentences, sentences_t, sentences_t2, sentences_t3, sentences_t4], [next_ope, next_ope_t, end_ope_t]\n",
    "    print('Vectorization...')\n",
    "    num_features = len(list_activities)+5 #1 order feature + 4 temporal features\n",
    "    print('num features: {}'.format(num_features))\n",
    "    X = np.zeros((num_samples, maxlen, num_features), dtype=np.float32)\n",
    "    Y = np.zeros(num_samples, dtype=np.float32)\n",
    "    for i, sentence in enumerate(prefixes[0]):\n",
    "        leftpad = maxlen-len(sentence)\n",
    "        end_t = outputs[2][i]\n",
    "        sentence_t = prefixes[1][i]\n",
    "        sentence_t2 = prefixes[2][i]\n",
    "        sentence_t3 = prefixes[3][i]\n",
    "        sentence_t4 = prefixes[4][i]\n",
    "        one_hot_act_matrix = encoder.transform(np.array(sentence).reshape((len(sentence), 1))).toarray()\n",
    "        for t, char in enumerate(sentence):                \n",
    "            X[i, t+leftpad, :len(list_activities)] = one_hot_act_matrix[t, :]\n",
    "            X[i, t+leftpad, len(list_activities)] = t+1 # order of the activity in the sequence {1,...,maxlen}\n",
    "            X[i, t+leftpad, len(list_activities)+1] = sentence_t[t]/divisor\n",
    "            X[i, t+leftpad, len(list_activities)+2] = sentence_t2[t]/divisor2\n",
    "            X[i, t+leftpad, len(list_activities)+3] = sentence_t3[t]/86400\n",
    "            X[i, t+leftpad, len(list_activities)+4] = sentence_t4[t]/7\n",
    "        Y[i] = end_t/divisor_rt\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfac5f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_activities = list(tab_all[\"Activity\"].unique())\n",
    "#creating instance of one-hot-encoder and fit on the whole dataset\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder.fit(np.array(list_activities).reshape((len(list_activities), 1)))\n",
    "\n",
    "lines, lines_t, lines_t2, lines_t3, lines_t4 = Extract_trace_and_temporal_features(tab_all)\n",
    "maxlen = max([len(x) for x in lines]) #find maximum line size\n",
    "lines, lines_t, lines_t2, lines_t3, lines_t4 = Extract_trace_and_temporal_features(tab_train)\n",
    "divisor = np.mean([item for sublist in lines_t for item in sublist]) #average time between events\n",
    "print('divisor: {}'.format(divisor))\n",
    "divisor2 = np.mean([item for sublist in lines_t2 for item in sublist]) #average time between current and first events\n",
    "print('divisor2: {}'.format(divisor2))\n",
    "prefixes, outputs = Extract_prefix(lines, lines_t, lines_t2, lines_t3, lines_t4)\n",
    "divisor_rt = np.mean(outputs[2])\n",
    "print('divisor_rt: {}'.format(divisor_rt))\n",
    "#Train data\n",
    "X_train, Y_train = Prepare_X_Y_remaining_time(tab_train, list_activities, divisor, divisor2, divisor_rt, encoder, maxlen)\n",
    "#Test data\n",
    "X_test, Y_test = Prepare_X_Y_remaining_time(tab_test, list_activities, divisor, divisor2, divisor_rt, encoder, maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2441fdbb",
   "metadata": {},
   "source": [
    "## Train LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c8f5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model: \n",
    "print('Build model...')\n",
    "main_input = Input(shape=(X_train.shape[1], X_train.shape[2]), name='main_input')\n",
    "# train a 2-layer LSTM with one shared layer\n",
    "l1 = LSTM(150, kernel_initializer='glorot_uniform', return_sequences=True, dropout=0.2)(main_input) # the shared layer\n",
    "b1 = BatchNormalization()(l1)\n",
    "\n",
    "l2_2 = LSTM(150, kernel_initializer='glorot_uniform', return_sequences=True, dropout=0.2)(b1) # the layer specialized in time prediction\n",
    "b2_2 = BatchNormalization()(l2_2)\n",
    "l3_2 = LSTM(150, kernel_initializer='glorot_uniform', return_sequences=True, dropout=0.2)(b2_2) \n",
    "b3_2 = BatchNormalization()(l3_2)\n",
    "l4_2 = LSTM(150, kernel_initializer='glorot_uniform', return_sequences=True, dropout=0.2)(b3_2) \n",
    "b4_2 = BatchNormalization()(l4_2)\n",
    "l5_2 = LSTM(150, kernel_initializer='glorot_uniform', return_sequences=False, dropout=0.2)(b4_2) \n",
    "b5_2 = BatchNormalization()(l5_2)\n",
    "# time prediction\n",
    "time_output = Dense(1, kernel_initializer='glorot_uniform')(b5_2)\n",
    "model = Model(inputs=[main_input], outputs=[time_output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea5af4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train\n",
    "num_epochs = 100\n",
    "early_stop_patience = 10\n",
    "min_delta = 0\n",
    "lr_value = 1e-03\n",
    "num_runs = 5\n",
    "running_time = []\n",
    "for run in range(num_runs):\n",
    "    start=datetime.datetime.now()\n",
    "    print(\"Run: {}\".format(run+1))\n",
    "    keras.backend.clear_session()\n",
    "    main_input = Input(shape=(X_train.shape[1], X_train.shape[2]), name='main_input')\n",
    "    # train a 2-layer LSTM with one shared layer\n",
    "    l1 = LSTM(150, kernel_initializer='glorot_uniform', return_sequences=True, dropout=0.2)(main_input) # the shared layer\n",
    "    b1 = BatchNormalization()(l1)\n",
    "\n",
    "    l2_2 = LSTM(150, kernel_initializer='glorot_uniform', return_sequences=True, dropout=0.2)(b1) # the layer specialized in time prediction\n",
    "    b2_2 = BatchNormalization()(l2_2)\n",
    "    l3_2 = LSTM(150, kernel_initializer='glorot_uniform', return_sequences=True, dropout=0.2)(b2_2) \n",
    "    b3_2 = BatchNormalization()(l3_2)\n",
    "    l4_2 = LSTM(150, kernel_initializer='glorot_uniform', return_sequences=True, dropout=0.2)(b3_2) \n",
    "    b4_2 = BatchNormalization()(l4_2)\n",
    "    l5_2 = LSTM(150, kernel_initializer='glorot_uniform', return_sequences=False, dropout=0.2)(b4_2) \n",
    "    b5_2 = BatchNormalization()(l5_2)\n",
    "    # time prediction\n",
    "    time_output = Dense(1, kernel_initializer='glorot_uniform')(b5_2)\n",
    "    model = Model(inputs=[main_input], outputs=[time_output])\n",
    "\n",
    "\n",
    "    opt = keras.optimizers.Adam(lr=lr_value)\n",
    "    model.compile(optimizer=opt, loss='mae', metrics=['mae'])\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=early_stop_patience, min_delta = min_delta)\n",
    "    model_checkpoint = ModelCheckpoint('../4_Outputs/Output_files/'+data_name+'_Tax_LSTM/best_model_run_{}.h5'.format(run+1),\n",
    "                                       monitor='val_loss', verbose=0, \n",
    "                                       save_best_only=True, save_weights_only=False, mode='min')\n",
    "    model.fit(X_train, Y_train, validation_split=0.2, \n",
    "              callbacks=[early_stopping, model_checkpoint], batch_size=16, epochs=num_epochs)\n",
    "    running_time.append((datetime.datetime.now()-start).total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fd9f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running time in average of each run: {}\".format(np.mean(running_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f79583",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189898f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(Y_actual,Y_Predicted):    \n",
    "    mape_mean = np.mean(np.abs((Y_actual - Y_Predicted)/Y_actual))*100\n",
    "    return mape_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ff3c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract test samples by prefix length\n",
    "prefix_size = X_test[:,-1,len(list_activities)]\n",
    "X_by_prefix_size = {}\n",
    "Y_by_prefix_size = {}\n",
    "for i in range(X_test.shape[0]):\n",
    "    prefix_size = X_test[i,-1,len(list_activities)]\n",
    "    if prefix_size in X_by_prefix_size.keys():\n",
    "        X_by_prefix_size[prefix_size].append(X_test[i,:,:])\n",
    "        Y_by_prefix_size[prefix_size].append(Y_test[i])\n",
    "    else:\n",
    "        X_by_prefix_size[prefix_size] = [X_test[i,:,:]]\n",
    "        Y_by_prefix_size[prefix_size] = [Y_test[i]]\n",
    "\n",
    "for key in X_by_prefix_size.keys():\n",
    "    X_by_prefix_size[key] = np.array(X_by_prefix_size[key])\n",
    "    Y_by_prefix_size[key] = np.array(Y_by_prefix_size[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111f4417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute MAE and MPAE error of test data for each run. Then the average and std are computed \n",
    "err_total_dict = {}\n",
    "for run in range(num_runs):\n",
    "    print(\"Run: {}\".format(run+1))\n",
    "    model = load_model('../4_Outputs/Output_files/'+data_name+'_Tax_LSTM/best_model_run_{}.h5'.format(run+1))\n",
    "    for key in X_by_prefix_size.keys():\n",
    "        y_predict = model.predict(X_by_prefix_size[key])\n",
    "        mape_err = MAPE(Y_by_prefix_size[key], y_predict)\n",
    "        mae_err = mean_absolute_error(Y_by_prefix_size[key], y_predict)*divisor_rt/86400\n",
    "        if key in err_total_dict.keys():\n",
    "            err_total_dict[key].append([mape_err, mae_err])\n",
    "        else:\n",
    "            err_total_dict[key] = [[mape_err, mae_err]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c63466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction errors by prefix length are then stored in a tab\n",
    "list_prefix_len = []\n",
    "list_num_samples = []\n",
    "list_mape_err = []\n",
    "list_mape_std = []\n",
    "list_mae_err = []\n",
    "list_mae_std = []\n",
    "for key, value in err_total_dict.items():\n",
    "    list_prefix_len.append(key)\n",
    "    list_num_samples.append(X_by_prefix_size[key].shape[0])\n",
    "    list_mape_err.append(round(np.array(value).mean(axis=0)[0], 3))\n",
    "    list_mape_std.append(round(np.array(value).std(axis=0)[0], 3))\n",
    "    list_mae_err.append(round(np.array(value).mean(axis=0)[1], 3))\n",
    "    list_mae_std.append(round(np.array(value).std(axis=0)[1], 3))\n",
    "tab_result = pd.DataFrame({\"Prefix length\":list_prefix_len, \"Num samples\": list_num_samples, \n",
    "                           \"MAPE(%)\":list_mape_err, \"MAPE std\": list_mape_std,\n",
    "                           \"MAE(days)\": list_mae_err, \"MAE std\": list_mae_std})\n",
    "\n",
    "if not os.path.exists(project_dir + '4_Outputs/Evaluation'):\n",
    "    os.mkdir(project_dir + '4_Outputs/Evaluation')\n",
    "tab_result.to_csv(project_dir+\"4_Outputs/Evaluation/\"+data_name+\"_Tax_LSTM_eval.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
