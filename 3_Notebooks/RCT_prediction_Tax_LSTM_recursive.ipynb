{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070c67e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import dirname\n",
    "root_path = dirname(dirname(os.getcwd()))\n",
    "print(root_path)\n",
    "import sys\n",
    "sys.path.append(root_path + '/RemainingCycleTimePrediction/2_Scripts/')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import datetime, time\n",
    "import multiprocessing\n",
    "import multiprocessing.dummy\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from ax.plot.contour import plot_contour\n",
    "from ax.plot.trace import optimization_trace_single_method\n",
    "from ax.service.managed_loop import optimize\n",
    "from ax.utils.notebook.plotting import render\n",
    "\n",
    "from Event_log_processing_utils import Extract_trace_and_temporal_features, Extract_prefix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "data_dir = root_path + '/RemainingCycleTimePrediction/1_Data/'\n",
    "project_dir = root_path + '/RemainingCycleTimePrediction/'\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32c7935",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f3e9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'BPIC20'\n",
    "# data_name = 'Helpdesk'\n",
    "# data_name = 'EMS3141BE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63f8cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_name == 'BPIC20':\n",
    "    end_act = \"Payment Handled\"\n",
    "elif data_name == 'Helpdesk':\n",
    "    end_act = \"Closed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff93497",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_all = pd.read_csv(data_dir+data_name+\"_processed_all.csv\")\n",
    "tab_train= pd.read_csv(data_dir+data_name+\"_processed_train.csv\")\n",
    "tab_valid= pd.read_csv(data_dir+data_name+\"_processed_valid.csv\")\n",
    "tab_test = pd.read_csv(data_dir+data_name+\"_processed_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0540c868",
   "metadata": {},
   "source": [
    "## 2. Prepare inputs and outputs for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55090026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prepare_X_Y_next_activity(tab, list_activities, divisor, divisor2, encoder, le, maxlen):\n",
    "    lines, lines_t, lines_t2, lines_t3, lines_t4 = Extract_trace_and_temporal_features(tab)\n",
    "    prefixes, outputs = Extract_prefix(lines, lines_t, lines_t2, lines_t3, lines_t4)\n",
    "    num_samples = len(prefixes[0])\n",
    "    print('Vectorization...')\n",
    "    num_features = len(list_activities)+5\n",
    "    print('num features: {}'.format(num_features))\n",
    "    X = np.zeros((num_samples, maxlen, num_features), dtype=np.float32)\n",
    "    y_a = np.zeros((num_samples), dtype=np.float32)\n",
    "    y_t = np.zeros((num_samples), dtype=np.float32)\n",
    "    for i, sentence in enumerate(prefixes[0]):\n",
    "        leftpad = maxlen-len(sentence)\n",
    "        next_t = outputs[1][i]\n",
    "        sentence_t = prefixes[1][i]\n",
    "        sentence_t2 = prefixes[2][i]\n",
    "        sentence_t3 = prefixes[3][i]\n",
    "        sentence_t4 = prefixes[4][i]\n",
    "        one_hot_act_matrix = encoder.transform(np.array(sentence).reshape((len(sentence), 1))).toarray()\n",
    "        for t, char in enumerate(sentence):                \n",
    "            X[i, t+leftpad, :len(list_activities)] = one_hot_act_matrix[t, :]\n",
    "            X[i, t+leftpad, len(list_activities)] = t+1 # order of the activity in the sequence {1,...,maxlen}\n",
    "            X[i, t+leftpad, len(list_activities)+1] = sentence_t[t]/divisor\n",
    "            X[i, t+leftpad, len(list_activities)+2] = sentence_t2[t]/divisor2\n",
    "            X[i, t+leftpad, len(list_activities)+3] = sentence_t3[t]/86400\n",
    "            X[i, t+leftpad, len(list_activities)+4] = sentence_t4[t]/7\n",
    "\n",
    "        y_a[i] = le.transform(np.array([[outputs[0][i]]]))\n",
    "\n",
    "        y_t[i] = next_t/divisor\n",
    "    return X, y_a, y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfac5f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_activities = list(tab_all[\"Activity\"].unique())\n",
    "num_activities = len(list_activities)\n",
    "num_features = len(list_activities)+5\n",
    "#creating instance of one-hot-encoder and fit on the whole dataset\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder.fit(np.array(list_activities).reshape((len(list_activities), 1)))\n",
    "# transform label from string to number\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(list_activities)\n",
    "\n",
    "lines, lines_t, lines_t2, lines_t3, lines_t4 = Extract_trace_and_temporal_features(tab_all)\n",
    "maxlen = max([len(x) for x in lines]) #find maximum line size\n",
    "lines, lines_t, lines_t2, lines_t3, lines_t4 = Extract_trace_and_temporal_features(tab_train)\n",
    "divisor = np.mean([item for sublist in lines_t for item in sublist]) #average time between events\n",
    "print('divisor: {}'.format(divisor))\n",
    "divisor2 = np.mean([item for sublist in lines_t2 for item in sublist]) #average time between current and first events\n",
    "print('divisor2: {}'.format(divisor2))\n",
    "#Train data\n",
    "X_train, y_a_train, y_t_train = Prepare_X_Y_next_activity(tab_train, list_activities, divisor, divisor2, encoder, le, maxlen)\n",
    "#Valid data\n",
    "X_valid, y_a_valid, y_t_valid = Prepare_X_Y_next_activity(tab_valid, list_activities, divisor, divisor2, encoder, le, maxlen)\n",
    "#Test data\n",
    "X_test, y_a_test, y_t_test = Prepare_X_Y_next_activity(tab_test, list_activities, divisor, divisor2, encoder, le, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75820a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventLogData(Dataset):\n",
    "    def __init__ (self, input_x, output_a, output_t):\n",
    "        self.X = input_x\n",
    "        self.y_a = output_a\n",
    "        self.y_a = self.y_a.to(torch.float32).reshape((len(self.y_a),1))\n",
    "        self.y_t = output_t\n",
    "        self.y_t = self.y_t.to(torch.float32).reshape((len(self.y_t),1))\n",
    "\n",
    "    #get the number of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    #get a row at a particular index in the dataset\n",
    "    def __getitem__ (self,idx):\n",
    "        return [self.X[idx],self.y_a[idx],self.y_t[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d80602d",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(EventLogData(torch.tensor(X_valid), torch.tensor(y_a_valid), torch.tensor(y_t_valid)),\n",
    "                                batch_size=X_valid.shape[0],\n",
    "                                shuffle=False)\n",
    "test_loader = DataLoader(EventLogData(torch.tensor(X_test), torch.tensor(y_a_test), torch.tensor(y_t_test)),\n",
    "                                batch_size=1,\n",
    "                                shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14456b99",
   "metadata": {},
   "source": [
    "## 3. Hyperparameter tuning with Ax package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc7cf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the LSTM class\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, parameterization):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_dim = parameterization.get(\"neurons\", 40)\n",
    "        self.num_shared_layers = parameterization.get(\"shared_layers\", 1)\n",
    "        self.num_layers = parameterization.get(\"layers\", 1)\n",
    "        self.droppout_prob = parameterization.get(\"dropout\", 0.2)\n",
    "                \n",
    "        self.lstm = nn.LSTM(input_size=num_features, hidden_size=self.hidden_dim, \n",
    "                            num_layers=self.num_shared_layers, batch_first=True, dropout=self.droppout_prob)   \n",
    "        self.lstm_a = nn.LSTM(input_size=self.hidden_dim, hidden_size=self.hidden_dim, \n",
    "                            num_layers=self.num_layers, batch_first=True, dropout=self.droppout_prob) \n",
    "        self.lstm_t = nn.LSTM(input_size=self.hidden_dim, hidden_size=self.hidden_dim, \n",
    "                            num_layers=self.num_layers, batch_first=True, dropout=self.droppout_prob)\n",
    "                \n",
    "        self.fc_a = nn.Linear(self.hidden_dim, num_activities)\n",
    "        self.fc_t = nn.Linear(self.hidden_dim, 1)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    \n",
    "    # Progresses data across layers    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0) \n",
    "        init_states_shared, init_cells_shared = self.init_hidden(batch_size, self.num_shared_layers)\n",
    "        init_states_shared = init_states_shared.to(x.device)\n",
    "        init_cells_shared = init_cells_shared.to(x.device)\n",
    "        \n",
    "        init_states, init_cells = self.init_hidden(batch_size, self.num_layers)\n",
    "        init_states = init_states.to(x.device)\n",
    "        init_cells = init_cells.to(x.device)\n",
    "                \n",
    "        shared_lstm_output, (last_Hidden_State, last_Cell_State) = self.lstm(x, (init_states_shared, init_cells_shared)) \n",
    "        lstm_output_a, (last_Hidden_State_a, last_Cell_State_a) = self.lstm_a(shared_lstm_output, \n",
    "                                                                                      (init_states, init_cells)) \n",
    "        lstm_output_t, (last_Hidden_State_t, last_Cell_State_t) = self.lstm_t(shared_lstm_output, \n",
    "                                                                                      (init_states, init_cells))\n",
    "        out_a = self.softmax(self.fc_a(last_Hidden_State_a[-1]))\n",
    "        \n",
    "        out_t = self.fc_t(last_Hidden_State_t[-1])\n",
    "        return out_a, out_t\n",
    "\n",
    "    def init_hidden(self, batch_size, num_layers):\n",
    "        init_states = []\n",
    "        init_cells = []\n",
    "        for i in range(num_layers):\n",
    "            init_states.append(torch.zeros(batch_size, self.hidden_dim))\n",
    "            init_cells.append(torch.zeros(batch_size, self.hidden_dim))\n",
    "        return torch.stack(init_states, dim=0), torch.stack(init_cells, dim=0)      #(num_layers, B, H)\n",
    "    \n",
    "    \n",
    "def net_train(net, train_loader, valid_loader, parameters, dtype, device, early_stop_patience):\n",
    "    net.to(dtype=dtype, device=device)\n",
    "    min_delta = 0\n",
    "    # Define loss and optimizer\n",
    "    criterion_a = nn.CrossEntropyLoss()\n",
    "    criterion_t = nn.L1Loss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=parameters.get(\"lr\", 0.001)) # 0.001 is used if no lr is specified    \n",
    "    num_epochs = 100 # Play around with epoch number\n",
    "    \n",
    "    # Train Network\n",
    "    not_improved_count = 0\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        training_loss = 0\n",
    "        num_train = 0\n",
    "        for inputs, labels_a, labels_t in train_loader:\n",
    "            # move data to proper dtype and device\n",
    "            inputs = inputs.to(dtype=dtype, device=device)\n",
    "            labels_a = labels_a.to(device=device)\n",
    "            labels_t = labels_t.to(device=device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            output_a, output_t = net(inputs)\n",
    "            loss_a = criterion_a(output_a, labels_a.to(torch.long).squeeze(1))\n",
    "            loss_t = criterion_t(output_t, labels_t)\n",
    "            # back prop\n",
    "            loss = loss_a + loss_t\n",
    "            loss.backward()\n",
    "            # optimize\n",
    "            optimizer.step()\n",
    "            training_loss += loss.item()\n",
    "            num_train+=1\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            num_valid = 0\n",
    "            validation_loss = 0\n",
    "            for i,(inputs,targets_a, targets_t) in enumerate(valid_loader):\n",
    "                inputs, targets_a, targets_t = inputs.to(device), targets_a.to(device), targets_t.to(device)\n",
    "                yhat_valid_a, yhat_valid_t = net(inputs)\n",
    "                loss_valid = criterion_a(yhat_valid_a,targets_a.to(torch.long).squeeze(1)) + criterion_t(yhat_valid_t,targets_t)\n",
    "                validation_loss+= loss_valid.item()\n",
    "                num_valid+= 1\n",
    "        avg_training_loss = training_loss/num_train\n",
    "        avg_validation_loss = validation_loss/num_valid        \n",
    "        print(\"Epoch: {}, Training loss : {}, Validation loss : {}\".format(epoch,avg_training_loss,avg_validation_loss))\n",
    "        if (epoch==0): \n",
    "            best_loss = avg_validation_loss\n",
    "            best_model = copy.deepcopy(net)\n",
    "        else:\n",
    "            if (best_loss - avg_validation_loss >= min_delta):\n",
    "                best_model = copy.deepcopy(net)\n",
    "                best_loss = avg_validation_loss\n",
    "                not_improved_count = 0\n",
    "            else:\n",
    "                not_improved_count += 1\n",
    "        # Early stopping\n",
    "        if not_improved_count == early_stop_patience:\n",
    "            print(\"Validation performance didn\\'t improve for {} epochs. \"\n",
    "                            \"Training stops.\".format(early_stop_patience))\n",
    "            break\n",
    "    training_time = time.time() - start_time\n",
    "    print(\"Training time:\", training_time)\n",
    "    return best_model\n",
    "\n",
    "\n",
    "def lstm_direct_evaluate(net, data_loader, dtype, device):\n",
    "    criterion_a = nn.CrossEntropyLoss()\n",
    "    criterion_t = nn.L1Loss()\n",
    "    net.eval()\n",
    "    loss = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i,(inputs,targets_a, targets_t) in enumerate(data_loader):\n",
    "            # move data to proper dtype and device\n",
    "            inputs = inputs.to(dtype=dtype, device=device)\n",
    "            targets_a, targets_t = targets_a.to(device=device), targets_t.to(device=device)\n",
    "            outputs_a, outputs_t = net(inputs)\n",
    "            loss += (criterion_a(outputs_a,targets_a.to(torch.long).squeeze(1)) + criterion_t(outputs_t,targets_t))\n",
    "            total += 1\n",
    "    return loss.item() / total\n",
    "\n",
    "\n",
    "def train_evaluate(parameterization):\n",
    "\n",
    "    # constructing a new training data loader allows us to tune the batch size\n",
    "    train_loader = DataLoader(EventLogData(torch.tensor(X_train), torch.tensor(y_a_train), torch.tensor(y_t_train)),\n",
    "                                batch_size=parameterization.get(\"batchsize\", 32),\n",
    "                                shuffle=True)\n",
    "    \n",
    "    # Get neural net\n",
    "    untrained_net = LSTM(parameterization)\n",
    "    # train\n",
    "    trained_net = net_train(net=untrained_net, train_loader=train_loader, valid_loader = valid_loader, \n",
    "                            parameters=parameterization, dtype=dtype, device=device, early_stop_patience = 10)\n",
    "    \n",
    "    # return the accuracy of the model as it was trained in this run\n",
    "    return lstm_direct_evaluate(\n",
    "        net=trained_net,\n",
    "        data_loader=valid_loader,\n",
    "        dtype=dtype,\n",
    "        device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf66d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "best_parameters, values, experiment, model = optimize(\n",
    "    parameters=[\n",
    "        {\"name\": \"neurons\", \"type\": \"choice\", \"values\": [40, 60, 80, 100], \"value_type\": \"int\"},\n",
    "        {\"name\": \"shared_layers\", \"type\": \"choice\", \"values\": [1, 2], \"value_type\": \"int\"},\n",
    "        {\"name\": \"layers\", \"type\": \"choice\", \"values\": [1, 2, 3], \"value_type\": \"int\"},\n",
    "        {\"name\": \"lr\", \"type\": \"range\", \"bounds\": [1e-4, 0.1], \"value_type\": \"float\", \"log_scale\": True},\n",
    "        {\"name\": \"batchsize\", \"type\": \"choice\", \"values\": [16, 32, 64], \"value_type\": \"int\"}, \n",
    "        {\"name\": \"dropout\", \"type\": \"range\", \"bounds\": [0, 0.5], \"value_type\": \"float\"}\n",
    "    ],\n",
    "  \n",
    "    evaluation_function=train_evaluate,\n",
    "    objective_name='loss',\n",
    "    minimize = True,\n",
    "    random_seed = 123,\n",
    "    total_trials = 100\n",
    ")\n",
    "\n",
    "print(best_parameters)\n",
    "means, covariances = values\n",
    "print(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b67f182",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = experiment.fetch_data()\n",
    "df = data.df\n",
    "best_arm_name = df.arm_name[df['mean'] == df['mean'].min()].values[0]\n",
    "best_arm = experiment.arms_by_name[best_arm_name]\n",
    "best_arm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2441fdbb",
   "metadata": {},
   "source": [
    "## 4. Re-train model with tuned hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c8f5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the LSTM class\n",
    "class LSTM_model(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_shared_layers, num_layers, droppout_prob):\n",
    "        super(LSTM_model, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_shared_layers = num_shared_layers\n",
    "        self.num_layers =  num_layers\n",
    "        self.droppout_prob = droppout_prob\n",
    "                \n",
    "        self.lstm = nn.LSTM(input_size=num_features, hidden_size=self.hidden_dim, \n",
    "                            num_layers=self.num_shared_layers, batch_first=True, dropout=self.droppout_prob) \n",
    "        self.lstm_a = nn.LSTM(input_size=self.hidden_dim, hidden_size=self.hidden_dim, \n",
    "                            num_layers=self.num_layers, batch_first=True, dropout=self.droppout_prob) \n",
    "        self.lstm_t = nn.LSTM(input_size=self.hidden_dim, hidden_size=self.hidden_dim, \n",
    "                            num_layers=self.num_layers, batch_first=True, dropout=self.droppout_prob)\n",
    "                \n",
    "        self.fc_a = nn.Linear(self.hidden_dim, num_activities)\n",
    "        self.fc_t = nn.Linear(self.hidden_dim, 1)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    \n",
    "    # Progresses data across layers    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0) \n",
    "        init_states_shared, init_cells_shared = self.init_hidden(batch_size, self.num_shared_layers)\n",
    "        init_states_shared = init_states_shared.to(x.device)\n",
    "        init_cells_shared = init_cells_shared.to(x.device)\n",
    "        \n",
    "        init_states, init_cells = self.init_hidden(batch_size, self.num_layers)\n",
    "        init_states = init_states.to(x.device)\n",
    "        init_cells = init_cells.to(x.device)\n",
    "                \n",
    "        shared_lstm_output, (last_Hidden_State, last_Cell_State) = self.lstm(x, (init_states_shared, init_cells_shared)) \n",
    "        lstm_output_a, (last_Hidden_State_a, last_Cell_State_a) = self.lstm_a(shared_lstm_output, \n",
    "                                                                                      (init_states, init_cells)) \n",
    "        lstm_output_t, (last_Hidden_State_t, last_Cell_State_t) = self.lstm_t(shared_lstm_output, \n",
    "                                                                                      (init_states, init_cells))\n",
    "        out_a = self.softmax(self.fc_a(last_Hidden_State_a[-1]))\n",
    "        \n",
    "        out_t = self.fc_t(last_Hidden_State_t[-1])\n",
    "        return out_a, out_t\n",
    "\n",
    "    def init_hidden(self, batch_size, num_layers):\n",
    "        init_states = []\n",
    "        init_cells = []\n",
    "        for i in range(num_layers):\n",
    "            init_states.append(torch.zeros(batch_size, self.hidden_dim))\n",
    "            init_cells.append(torch.zeros(batch_size, self.hidden_dim))\n",
    "        return torch.stack(init_states, dim=0), torch.stack(init_cells, dim=0)      #(num_layers, B, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f886268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = best_arm.parameters['batchsize']\n",
    "\n",
    "train_loader = DataLoader(EventLogData(torch.tensor(X_train), torch.tensor(y_a_train), torch.tensor(y_t_train)),\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea5af4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_folder = project_dir + '5_Output_files/Remaining_time_prediction/'+data_name+'_Tax_LSTM_direct'\n",
    "hidden_dim = best_arm.parameters['neurons']\n",
    "num_layers = best_arm.parameters['layers']\n",
    "droppout_prob = best_arm.parameters['dropout']\n",
    "lr_value = best_arm.parameters['lr']\n",
    "min_delta = 0\n",
    "num_epochs = 100\n",
    "early_stop_patience = 10\n",
    "num_runs = 5\n",
    "# Define loss and optimizer   \n",
    "for run in range(num_runs):\n",
    "    print(\"Run: {}\".format(run+1))\n",
    "    model = LSTM_direct_model(hidden_dim, num_layers, droppout_prob)\n",
    "    model.to(dtype=dtype, device=device) \n",
    "    criterion = nn.L1Loss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr_value)\n",
    "    epochs_plt = []\n",
    "    mae_plt = []\n",
    "    valid_loss_plt = []\n",
    "    not_improved_count = 0\n",
    "    # Train Network   \n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        training_loss = 0\n",
    "        num_train = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            # move data to proper dtype and device\n",
    "            inputs = inputs.to(dtype=dtype, device=device)\n",
    "            labels = labels.to(device=device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            output = model(inputs)\n",
    "            loss = criterion(output, labels)\n",
    "            # back prop\n",
    "            loss.backward()\n",
    "            # optimize\n",
    "            optimizer.step()\n",
    "            training_loss+= loss.item()\n",
    "            num_train+=1\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            num_valid = 0\n",
    "            validation_loss = 0\n",
    "            for i,(inputs,targets) in enumerate(valid_loader):\n",
    "                inputs,targets = inputs.to(device),targets.to(device)\n",
    "                yhat_valid = model(inputs)\n",
    "                loss_valid = criterion(yhat_valid,targets)\n",
    "                validation_loss+= loss_valid.item()\n",
    "                num_valid+= 1\n",
    "        avg_training_loss = training_loss/num_train\n",
    "        avg_validation_loss = validation_loss/num_valid        \n",
    "        print(\"Epoch: {}, Training MAE : {}, Validation loss : {}\".format(epoch,avg_training_loss,avg_validation_loss))\n",
    "        epochs_plt.append(epoch+1)\n",
    "        mae_plt.append(avg_training_loss)\n",
    "        valid_loss_plt.append(avg_validation_loss)\n",
    "        if (epoch==0): \n",
    "            best_loss = avg_validation_loss\n",
    "            torch.save(model.state_dict(),'{}/best_model_run_{}.pt'.format(save_folder,run+1))\n",
    "            best_model = copy.deepcopy(model)\n",
    "        else:\n",
    "            if (best_loss - avg_validation_loss >= min_delta):\n",
    "                torch.save(model.state_dict(),'{}/best_model_run_{}.pt'.format(save_folder,run+1))\n",
    "                best_model = copy.deepcopy(model)\n",
    "                best_loss = avg_validation_loss\n",
    "                not_improved_count = 0\n",
    "            else:\n",
    "                not_improved_count += 1\n",
    "        # Early stopping\n",
    "        if not_improved_count == early_stop_patience:\n",
    "            print(\"Validation performance didn\\'t improve for {} epochs. \"\n",
    "                            \"Training stops.\".format(early_stop_patience))\n",
    "            break\n",
    "    training_time = time.time() - start_time\n",
    "    print(\"Training time:\", training_time)\n",
    "    filepath = '{}/Loss_'.format(save_folder)+data_name+'_run{}.txt'.format(run)    \n",
    "    with open(filepath, 'w') as file:\n",
    "        for item in zip(epochs_plt,mae_plt,valid_loss_plt):\n",
    "            file.write(\"{}\\n\".format(item))\n",
    "        file.write(\"Running time: {}\\n\".format(training_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f79583",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189898f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_trace_and_timed_features_rt(tab):\n",
    "    # Extract trace and compute the 4 timed features for each event\n",
    "    lastcase = ''\n",
    "    line = [] # to store all activities of each case\n",
    "    firstLine = True\n",
    "    lines = [] # to store activities of all cases\n",
    "    lines_t = [] # to store all timediff from last event of all cases\n",
    "    lines_t2 = [] # to store all timediff2 from start case event of all cases\n",
    "    lines_t3 = [] # to store all timediff3 from midnight of all cases\n",
    "    lines_t4 = [] # to store all timediff4 day in week of all cases\n",
    "    lines_t5 = [] # to store the time of current event\n",
    "    times = []  # to store all timediff in a case\n",
    "    times2 = [] # to store all timediff2 in a case\n",
    "    times3 = [] # to store all timediff3 in a case\n",
    "    times4 = [] # to store all timediff4 in a case\n",
    "    times5 = [] # to store all t5 in a case\n",
    "    casestarttime = None\n",
    "    lasteventtime = None\n",
    "    for i in range(len(tab)):\n",
    "        t = time.mktime(datetime.datetime.strptime(tab['timestamp'][i],\"%Y/%m/%d %H:%M:%S\").timetuple())\n",
    "        if tab['Case_ID'][i] != lastcase: # if its a new case\n",
    "            casestarttime = t\n",
    "            lasteventtime = t\n",
    "            lastcase = tab['Case_ID'][i]\n",
    "            if not firstLine: # add the previous case\n",
    "                lines.append(line)\n",
    "                lines_t.append(times)\n",
    "                lines_t2.append(times2)\n",
    "                lines_t3.append(times3)\n",
    "                lines_t4.append(times4)\n",
    "                lines_t5.append(times5)\n",
    "            line = []\n",
    "            times = []\n",
    "            times2 = []\n",
    "            times3 = []\n",
    "            times4 = []\n",
    "            times5 = []\n",
    "        line.append(tab['Activity'][i])\n",
    "        timesincelastevent = t - lasteventtime\n",
    "        timesincecasestart = t - casestarttime\n",
    "        midnight = datetime.datetime.fromtimestamp(t).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "        current_time = datetime.datetime.fromtimestamp(t)\n",
    "        timesincemidnight = (current_time-midnight).total_seconds()\n",
    "        dayinweek = current_time.weekday() #day of the week\n",
    "        times.append(timesincelastevent)\n",
    "        times2.append(timesincecasestart)\n",
    "        times3.append(timesincemidnight)\n",
    "        times4.append(dayinweek)\n",
    "        times5.append(current_time)\n",
    "        lasteventtime = t\n",
    "        firstLine = False\n",
    "\n",
    "    # add the last case\n",
    "    lines.append(line)\n",
    "    lines_t.append(times)\n",
    "    lines_t2.append(times2)\n",
    "    lines_t3.append(times3)\n",
    "    lines_t4.append(times4)\n",
    "    lines_t5.append(times5)\n",
    "    return lines, lines_t, lines_t2, lines_t3, lines_t4, lines_t5\n",
    "\n",
    "\n",
    "def Extract_prefix_remaining_time(lines, lines_t, lines_t2, lines_t3, lines_t4, lines_t5):\n",
    "    step = 1\n",
    "    sentences = []\n",
    "    end_ope = []\n",
    "    sentences_t = []\n",
    "    sentences_t2 = []\n",
    "    sentences_t3 = []\n",
    "    sentences_t4 = []\n",
    "    sentences_t5 = []\n",
    "    end_ope_t = []\n",
    "    for line, line_t, line_t2, line_t3, line_t4, line_t5 in zip(lines, lines_t, lines_t2, lines_t3, lines_t4, lines_t5):\n",
    "        for i in range(2, len(line), step):\n",
    "            sentences.append(line[0: i])\n",
    "            sentences_t.append(line_t[0:i])\n",
    "            sentences_t2.append(line_t2[0:i])\n",
    "            sentences_t3.append(line_t3[0:i])\n",
    "            sentences_t4.append(line_t4[0:i])\n",
    "            sentences_t5.append(line_t5[0:i])\n",
    "            end_ope.append(line[-1])\n",
    "            end_ope_t.append(line_t2[-1] - line_t2[i-1])\n",
    "    return sentences, sentences_t, sentences_t2, sentences_t3, sentences_t4, sentences_t5, end_ope, end_ope_t\n",
    "\n",
    "def encode(sentence, sentence_t, sentence_t5, num_features, maxlen, encoder, divisor, divisor2):\n",
    "    X = np.zeros((1, maxlen, num_features), dtype=np.float32)\n",
    "    leftpad = maxlen-len(sentence)\n",
    "    times2 = np.cumsum(sentence_t)\n",
    "    one_hot_act_matrix = encoder.transform(np.array(sentence).reshape((len(sentence), 1))).toarray()\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[0, t+leftpad, :num_features-5] = one_hot_act_matrix[t, :]        \n",
    "        midnight = sentence_t5[t].replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "        timesincemidnight = sentence_t5[t]-midnight\n",
    "        X[0, t+leftpad, num_features-5] = t+1\n",
    "        X[0, t+leftpad, num_features-4] = sentence_t[t]/divisor\n",
    "        X[0, t+leftpad, num_features-3] = times2[t]/divisor2\n",
    "        X[0, t+leftpad, num_features-2] = timesincemidnight.seconds/86400\n",
    "        X[0, t+leftpad, num_features-1] = sentence_t5[t].weekday()/7\n",
    "    return X\n",
    "\n",
    "\n",
    "def remaining_time_pred_recursive_MP(input_prefixes, model,\n",
    "                                  num_features, maxlen, encoder, divisor, divisor2):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    def model_predict(input_prefix):\n",
    "        sentence, sentence_t, sentence_t5, end_ope_t = copy.deepcopy(input_prefix)\n",
    "#         total_sequence = copy.deepcopy(sentence)\n",
    "#         total_time = copy.deepcopy(sentence_t)\n",
    "        prefix_size = len(sentence)\n",
    "        for i in range(prefix_size, maxlen):\n",
    "            X_test = encode(sentence, sentence_t, sentence_t5, num_features, maxlen, encoder, divisor, divisor2)\n",
    "            X_test = torch.from_numpy(X_test).to(device)\n",
    "            y_a_predict, y_t_predict = model(X_test)\n",
    "            binary_vect = 1*(y_a_predict >= y_a_predict.max()).squeeze()\n",
    "            numeric_class = (binary_vect == 1).nonzero(as_tuple=True)[0].item()\n",
    "            next_a = le.inverse_transform([numeric_class])[0]\n",
    "            delta_t = y_t_predict.item()*divisor\n",
    "#             total_sequence.append(next_a)\n",
    "#             total_time.append(delta_t)\n",
    "            next_t = sentence_t5[-1] + datetime.timedelta(seconds = delta_t)\n",
    "            if next_a != end_act:\n",
    "                sentence.append(next_a)\n",
    "                sentence_t.append(y_t_predict.item())           \n",
    "                sentence_t5.append(next_t)\n",
    "            else:\n",
    "                break\n",
    "        rt = (next_t - sentence_t5[prefix_size-1]).total_seconds()\n",
    "        return rt, end_ope_t, prefix_size\n",
    "    \n",
    "    list_rts = []\n",
    "    list_end_ope_t = []\n",
    "    list_prefixe_size = []\n",
    "    l = len(input_prefixes)\n",
    "    nb_processes = multiprocessing.cpu_count()\n",
    "    pool = multiprocessing.dummy.Pool(processes = nb_processes)  \n",
    "    try:\n",
    "        for i, data in enumerate(pool.imap_unordered(model_predict, input_prefixes)):\n",
    "            list_rts.append(data[0]) \n",
    "            list_end_ope_t.append(data[1])\n",
    "            list_prefixe_size.append(data[2])\n",
    "            printProgress(i, l, prefix='Predicting from {}'.format(l) + ' samples',\n",
    "                  suffix='already completed {}'.format(i + 1),\n",
    "                  decimals=0, barLength=40)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"got Ctrl+C\")\n",
    "    finally:\n",
    "        pool.terminate()\n",
    "        pool.join()   \n",
    "    return list_rts, list_end_ope_t, list_prefixe_size\n",
    "\n",
    "\n",
    "def printProgress (iteration, total, prefix = '', suffix = '', decimals = 1, barLength = 100, fill = 'â–ˆ'):\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        barLength   - Optional  : character length of bar (Int)\n",
    "    \"\"\"\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(barLength * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (barLength - filledLength)\n",
    "    sys.stdout.write('\\r%s |%s| %s%s %s' % (prefix, bar, percent, '%', suffix))\n",
    "#     if iteration == total:\n",
    "#         sys.stdout.write('\\n')\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ff3c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "lines, lines_t, lines_t2, lines_t3, lines_t4, lines_t5 = Extract_trace_and_timed_features_rt(tab_test)\n",
    "sentences, sentences_t, sentences_t2, sentences_t3, sentences_t4, sentences_t5, end_ope, end_ope_t = Extract_prefix_remaining_time(lines, lines_t, lines_t2, lines_t3, lines_t4, lines_t5)\n",
    "\n",
    "list_inputs = [[sentences[i].copy(), sentences_t[i].copy(), sentences_t5[i].copy(), end_ope_t[i]] for i in range(len(sentences))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111f4417",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples_dict = {}\n",
    "for sentence in sentences:\n",
    "    key = len(sentence)\n",
    "    if key in num_samples_dict.keys():\n",
    "        num_samples_dict[key] += 1\n",
    "    else:\n",
    "        num_samples_dict[key] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c63466",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 5\n",
    "list_mae_time = []\n",
    "list_mape_time = []\n",
    "err_total_dict = {}\n",
    "for run in range(num_runs):\n",
    "    print(\"Run: {}\".format(run+1))\n",
    "    trained_model = LSTM_model(hidden_dim, num_shared_layers, num_layers, droppout_prob)\n",
    "    trained_model.load_state_dict(torch.load('{}/best_model_run_{}.pt'.format(save_folder,run+1),\n",
    "                                         map_location=torch.device(device)))\n",
    "    list_rts, list_rts_true, list_prefixe_size = remaining_time_pred_recursive_MP(list_inputs, trained_model,\n",
    "                                  num_features, maxlen, encoder, divisor, divisor2)\n",
    "    tab_results = pd.DataFrame({'Prefix length':list_prefixe_size, 'Y_predicted': list_rts, 'Y_true': list_rts_true})\n",
    "    for key in list(tab_results['Prefix length'].unique()):\n",
    "        filtered_tab = tab_results[tab_results['Prefix length']==key]\n",
    "        mae_err = metrics.mean_absolute_error(filtered_tab['Y_predicted'], filtered_tab['Y_true'])/86400\n",
    "        mape_err = np.mean(np.abs((filtered_tab['Y_true'] - filtered_tab['Y_predicted'])/filtered_tab['Y_true']))*100\n",
    "        if key in err_total_dict.keys():\n",
    "            err_total_dict[key].append([mape_err, mae_err])\n",
    "        else:\n",
    "            err_total_dict[key] = [[mape_err, mae_err]]\n",
    "    mae_t = metrics.mean_absolute_error(list_rts, list_rts_true)/86400\n",
    "    list_mae_time.append(round(mae_t,2))\n",
    "    mape_t = np.mean(np.abs((np.array(list_rts_true)- np.array(list_rts))/np.array(list_rts_true)))*100\n",
    "    list_mape_time.append(round(mape_t,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7747a280",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_prefix_len = []\n",
    "list_num_samples = []\n",
    "list_mape_err = []\n",
    "list_mape_std = []\n",
    "list_mae_err = []\n",
    "list_mae_std = []\n",
    "for key, value in err_total_dict.items():\n",
    "    list_prefix_len.append(key)\n",
    "    list_num_samples.append(num_samples_dict[key])\n",
    "    list_mape_err.append(round(np.array(err_total_dict[key]).mean(axis = 0)[0], 3))\n",
    "    list_mape_std.append(round(np.array(err_total_dict[key]).std(axis = 0)[0], 3))\n",
    "    list_mae_err.append(round(np.array(err_total_dict[key]).mean(axis = 0)[1], 3))\n",
    "    list_mae_std.append(round(np.array(err_total_dict[key]).std(axis = 0)[1], 3))\n",
    "tab_result = pd.DataFrame({\"Prefix length\":list_prefix_len, \"Num samples\": list_num_samples, \n",
    "                           \"MAPE(%)\":list_mape_err, \"MAPE std\": list_mape_std,\n",
    "                           \"MAE(days)\": list_mae_err, \"MAE std\": list_mae_std})\n",
    "tab_result = tab_result.sort_values('Prefix length')\n",
    "tab_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72914c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = tab_result[tab_result[\"Num samples\"] >= 20]\n",
    "sum(tab[\"Num samples\"]*tab[\"MAE(days)\"])/sum(tab[\"Num samples\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed1b2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_result.to_csv(project_dir+\"4_Outputs/Evaluation/\"+data_name+\"_Tax_LSTM_recursive_eval.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_python3)",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
